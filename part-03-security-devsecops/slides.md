# Part 3: Security, Licensing & Governance

---

## Security Risks with AI in DevSecOps

### What risks do YOU see?

- Unsafe code?
- Prompt injection?
- Copyright errors?
- Vendor lock-in?
- Cost at scale?

**Let's discuss...**

---

## Same Pattern as Lab 1

### Tools → Extract → Prompt → Report

**Black Duck Source Identification:**

- **Tools:** Black Duck reports, source files
- **Extract:** Relevant code sections
- **Prompt:** Structured query
- **Report:** Evidence-based output

*You've seen this pattern before - Lab 1!*

---

## Evidence or It Doesn't Ship

### Key Principles

- ✅ AI generates suggestions
- ✅ Humans review and decide
- ✅ Always require evidence
- ✅ Never trust blindly

**Guardrail:** Human review always required for final attribution

---

## Takeaway

> "AI doesn't replace CodeQL/Coverity/Black Duck - it helps prioritize and explain their findings."

**For copyright scanning:**
- AI speeds up source identification by 70-80%
- Human review always required for final attribution

